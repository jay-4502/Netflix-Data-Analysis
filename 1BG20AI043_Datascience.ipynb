{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc7e780-908a-44d3-a622-f7094b1a01b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import seaborn as sns\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf812e48-a6f2-48ca-be57-61d46a90beed",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'DATA/netflix_titles.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDATA/netflix_titles.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DATA/netflix_titles.csv'"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"DATA/netflix_titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757cf23a-2eac-4405-ab11-b915144bb989",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef845c-32da-4460-8b7a-b8e71a2c49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c05ca-e3bc-42ab-bf4b-1dc8a3e65ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964180a-610f-4514-9b8a-2d571681764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3f89fc-86c1-40ed-a8cc-e580c19f377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eabe8bd-f096-4ebc-a5b3-732386c7b30f",
   "metadata": {},
   "source": [
    "## Checking and solving for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd3d3a-6eb6-4ad5-abb6-4f190f2a3570",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate=data.duplicated()\n",
    "duplicate_count=sum(data.duplicated())\n",
    "print(\"there are\",duplicate_count,\"duplicates in the dataset\")\n",
    "if duplicate_count>0:\n",
    "    print(\"duplicate data: \",data[duplicate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa823c1-f5b7-483d-9867-37d0193fd3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the shape of data before removal of duplicate\n",
    "print(\"Data shape before duplicate removal:\", data.shape)\n",
    "\n",
    "# Deletes duplicate\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Prints the shape of data before removal of duplicate\n",
    "print(\"Data shape after duplicate removal:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c568567-c350-45c1-a681-69ebc5e5e0b1",
   "metadata": {},
   "source": [
    "## Checking for missing values and Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd604065-7d6e-4a9d-af01-ed0f614df498",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924c6b5-6e44-4e74-84e3-cd28cb8dfb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values=data.isna().sum()\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa3de76-0ea9-40f5-81e2-751c12e75e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(\"?\", np.nan, inplace=True)\n",
    "# Separate numeric and categorical columns\n",
    "numeric_columns = data.select_dtypes(include=np.number).columns\n",
    "categorical_columns = data.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# Handle missing values in numeric columns\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data[numeric_columns] = imputer.fit_transform(data[numeric_columns])\n",
    "\n",
    "# Handle missing values in categorical columns\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "data[categorical_columns] = imputer.fit_transform(data[categorical_columns])\n",
    "missing_value=data.isna().sum()\n",
    "print(missing_value[missing_value > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a4343-f294-4f25-b9c1-cd1ec029e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41ccf37-9e00-41fb-a9ee-2b4b357e7e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c70390a-25f9-4b8e-8d45-ef6286b64711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrating in the form of pie chart\n",
    "labels=[\"Movies\",\"TV Show\"]\n",
    "size=data[\"type\"].value_counts()\n",
    "colors = ['#FF6D00', '#FFD600']\n",
    "explode=[0,0.2]\n",
    "plt.rcParams[\"figure.figsize\"]=(5,5)\n",
    "plt.pie(size,labels = labels, colors= colors, explode = explode, shadow= True, startangle=15,autopct=\"%1.2f\")\n",
    "plt.title(\"Distribution of Movies and TV Shows\", fontsize=15)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab74e70a-cce0-4f58-bac8-79d20c3db324",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=(data.dtypes=='object')\n",
    "cat_cols=list(s[s].index)\n",
    "cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715e051-d138-4b35-9397-118378b29a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cardinality_cols = [cname for cname in cat_cols if data[cname].nunique() < 30]\n",
    "low_cardinality_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90d6ec-2afa-4775-a805-cbe6cbdb02c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up of missing data\n",
    "data=data.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9d48d0-b289-4a24-a10a-cdf9e868b45c",
   "metadata": {},
   "source": [
    "## Fixing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef5b25-aa9e-4bb4-a7bd-f2b3aa211ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing outliers using box-cox transformation\n",
    "\n",
    "# Select the numeric columns to apply Box-Cox transformation\n",
    "numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Loop through each numeric column and apply Box-Cox transformation\n",
    "for column in numeric_columns:\n",
    "    # Check the distribution of the original data\n",
    "    plt.hist(data[column], bins=20)\n",
    "    plt.title(\"Original Data Distribution - {}\".format(column))\n",
    "    plt.show()\n",
    "\n",
    "    # Apply Box-Cox transformation\n",
    "    transformed_data, lambda_value = boxcox(data[column])\n",
    "\n",
    "    # Check the distribution of the transformed data\n",
    "    plt.hist(transformed_data, bins=20)\n",
    "    plt.title(\"Transformed Data Distribution - {}\".format(column))\n",
    "    plt.show()\n",
    "\n",
    "    # Print the optimal lambda value\n",
    "    print(\"Optimal lambda value for {}: {}\".format(column, lambda_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c28061-aa88-4e72-9d55-4dce01936ca3",
   "metadata": {},
   "source": [
    "## Fixing errors, naming conventions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3fb64c-d14d-4e9d-abfa-86d66c2adadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numeric features\n",
    "numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = StandardScaler()\n",
    "data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Check the preprocessed dataset\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3393cc3-c4b0-47d3-9e97-0d1000b1378e",
   "metadata": {},
   "source": [
    "## Data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212588c3-b18c-460d-80e7-aa4ea7522c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_date_format = \"%Y-%m-%d\"\n",
    "invalid_dates = []\n",
    "movie_data=data.copy()\n",
    "for date in movie_data[\"release_year\"]:\n",
    "    try:\n",
    "        pd.to_datetime(date, format=valid_date_format)\n",
    "    except ValueError:\n",
    "        invalid_dates.append(date)\n",
    "if invalid_dates:\n",
    "    print(f\"Invalid release dates found: {', '.join(invalid_dates)}\")\n",
    "else:\n",
    "    print(\"The given dataset is validated as the year is in the specified format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0de73a-5bac-47a6-8001-1d8f1be625f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_data=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e1983-d178-40c7-84e5-4437e76dd793",
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8aaf07-2531-4565-9634-24e1eb94a0c0",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa5b4d7-4197-4710-b9c3-1350e1f03cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31404560-a0e6-4af6-9da2-cc897f9cdaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the relevant variables for SVM classification\n",
    "selected_columns = ['show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added',\n",
    "                     'release_year', 'rating', 'duration', 'listed_in', 'description']\n",
    "\n",
    "# Subset the data with the selected columns\n",
    "data_1 = netflix_data[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9ad1a-a1c6-41fa-8c45-807820e34015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = data_1.drop('type', axis=1) \n",
    "y = data_1['type'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_unique_labels, train_unique_label_count = np.unique(y_train, return_counts=True)\n",
    "\n",
    "test_unique_labels, test_unique_label_count = np.unique(y_test, return_counts=True)\n",
    "\n",
    "print(\"Train set distribution:\\n\")\n",
    "print(train_unique_labels, np.round(train_unique_label_count/X_train.shape[0], 2))\n",
    "\n",
    "print(\"\\nTest set distribution:\\n\")\n",
    "print(test_unique_labels, np.round(test_unique_label_count/X_test.shape[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107a08b0-e12a-456d-93c2-df8136394885",
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_svm_pipeline = Pipeline([\n",
    "    (\"poly_features\", PolynomialFeatures(degree=3)),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\"))\n",
    "    ])\n",
    "polynomial_svm_cross_val_scores = cross_val_score(\n",
    "    polynomial_svm_pipeline, X_train, y_train, scoring=\"accuracy\", cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb22b79-8083-4ce9-91ad-9e9220555f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Score: {} \\nMean Score Std. Dev.: {}\".format(\n",
    "    np.mean(polynomial_svm_cross_val_scores), \n",
    "    np.std(polynomial_svm_cross_val_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a9415-9a85-47ba-8d4b-644d51491dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18607471-2434-4027-b7e2-8e1705f530bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fcfadc-e71a-4bb9-8cd3-f0b829bf7f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c7cf0-a50c-494f-ab1f-821f833c9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3034ef1f-1125-410b-bc19-5381bb7008cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_1,hue=\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c315f2f-d5db-47b6-83e3-03b85a5dcc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_1,hue=\"release_year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc474bd-42c0-47d2-8d7a-cbc4a5391e4e",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef33ee3-d6d2-4c0a-8954-ab2d8db0f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ab3da-1fce-423e-8fca-274d2e533cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added',\n",
    "                     'release_year', 'rating', 'duration', 'listed_in', 'description']\n",
    "\n",
    "data = netflix_data[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c203a58a-75db-4266-b8ba-1dccd53ef196",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_1.drop('type', axis=1) \n",
    "y = data_1['type'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f96a76-1fcb-4328-a015-b43e246792c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ff9fc4-5d19-4643-a13b-ff13a62e4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f36e8af-ffa1-4477-a6ef-8975b8f52a13",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50caa0e6-95ee-43f7-8a47-547933ffff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "selected_columns = ['type', 'rating'] \n",
    "\n",
    "data = netflix_data[selected_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee995d49-e822-403b-a5c4-371b072045f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113304f6-4c69-44a7-961a-8b6ff9eb11c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
